{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as p\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torchmetrics import JaccardIndex\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from ternausnet.models import UNet16, UNet11\n",
    "# from config import CUDA_DEVICE\n",
    "from customDataFolderInria import ImageFolderInria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\"\"\"Global Parameters\"\"\"\n",
    "indira_dataset_path = \"/mnt/data1/yl241/datasets/Inria_Aerial/AerialImageDataset/\"\n",
    "network_weight_path = \"./weight/\"\n",
    "CUDA_DEVICE = 'cpu'  # parsed in main\n",
    "version = None  # defined in main\n",
    "model_name = None  # defined in main\n",
    "num_workers_train = 18\n",
    "batch_size = 8\n",
    "\n",
    "\"Hyper Parameters\"\n",
    "init_lr = 1e-4\n",
    "epoch = 500\n",
    "PROB_THRESHOLD = .5  # for visualizing inference output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def print_params():\n",
    "    print(\"######## Basics ##################\")\n",
    "    print(\"version: {}\".format(version))\n",
    "    print(\"Training on {}\".format(CUDA_DEVICE))\n",
    "    print(\"batch size = \", batch_size)\n",
    "    print(\"number of workers = \", num_workers_train)\n",
    "    print(\"#################################\")\n",
    "\n",
    "\n",
    "def load_data(dataset_path, sampler=None):\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        ImageFolderInria(root=dataset_path),\n",
    "        batch_size=batch_size, num_workers=num_workers_train, sampler=sampler)\n",
    "    return data_loader\n",
    "\n",
    "\n",
    "def load_network_weights(net, path):\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def save_network_weights(net, ep=None):\n",
    "    filename = network_weight_path + \"{}{}_epoch_{}.pth\".format(model_name, version, ep)\n",
    "    torch.save(net.state_dict(), filename)\n",
    "    print(\"network weights saved to \", filename)\n",
    "    return\n",
    "\n",
    "\n",
    "def compute_loss(output, label):\n",
    "    # debug\n",
    "    # assert(not torch.isnan(output).any())\n",
    "\n",
    "    bce_criterion = nn.BCELoss()\n",
    "    bce_loss = bce_criterion(output, label)\n",
    "    jaccard_criterion = JaccardIndex(num_classes=2, threshold=PROB_THRESHOLD).to(CUDA_DEVICE)\n",
    "    iou_loss = jaccard_criterion(output, label.type(torch.int8))\n",
    "    iou_loss.requires_grad = True\n",
    "    total_loss = bce_loss - torch.log(iou_loss)\n",
    "    return total_loss, bce_loss, iou_loss\n",
    "\n",
    "\n",
    "def tensorboard_vis(tb, ep, mode='train', input_=None, output=None, label=None):\n",
    "    tb.add_histogram(\"{}/output_\".format(mode), output, global_step=ep)\n",
    "    tb.add_histogram(\"{}/label_\".format(mode), label, global_step=ep)\n",
    "    if input_ is not None:\n",
    "        input_img_grid = torchvision.utils.make_grid(input_)\n",
    "        tb.add_image(\"{}/input\".format(mode), input_img_grid, global_step=ep)\n",
    "    if output is not None:\n",
    "        if mode == 'train':  # no threshold in visualization\n",
    "            output_img_grid = torchvision.utils.make_grid(output)\n",
    "            tb.add_image(\"{}/output\".format(mode), output_img_grid, global_step=ep)\n",
    "        elif mode == 'dev':  # apply threshold in visualization\n",
    "            clipped_output = output > PROB_THRESHOLD\n",
    "            output_img_grid = torchvision.utils.make_grid(clipped_output)\n",
    "            tb.add_image(\"{}/output\".format(mode), output_img_grid, global_step=ep)\n",
    "    if label is not None:\n",
    "        label_img_grid = torchvision.utils.make_grid(label)\n",
    "        tb.add_image(\"{}/label\".format(mode), label_img_grid, global_step=ep)\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def train_dev(net, tb, load_weights, pre_trained_params_path=None):\n",
    "    print_params()\n",
    "    net.to(CUDA_DEVICE)\n",
    "    net.train()\n",
    "    if load_weights:\n",
    "        load_network_weights(net, pre_trained_params_path)\n",
    "\n",
    "    # splitting train/dev set\n",
    "    validation_split = .2\n",
    "    dataset = ImageFolderInria(root=p.join(indira_dataset_path, \"train\"))\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(validation_split * dataset_size))\n",
    "    train_indices, dev_indices = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    dev_sampler = SubsetRandomSampler(dev_indices)\n",
    "    train_loader = load_data(p.join(indira_dataset_path, \"train\"), sampler=train_sampler)\n",
    "    dev_loader = load_data(p.join(indira_dataset_path, \"train\"), sampler=dev_sampler)\n",
    "    print(\"Using cross-validation with a {:.0%}/{:.0%} train/dev split:\".format(1 - validation_split, validation_split))\n",
    "    print(\"dev set: entry {} to {} | train set: entry {} to {}\"\n",
    "          .format(dev_indices[0], dev_indices[-1], train_indices[0], train_indices[-1]))\n",
    "    print(\"size of train set = {} mini-batches | size of dev set = {} mini-batches\".format(len(train_loader),\n",
    "                                                                                           len(dev_loader)))\n",
    "    train_num_mini_batches, dev_num_mini_batches = len(train_loader), len(dev_loader)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=init_lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=.98)\n",
    "    running_train_loss, running_dev_loss = 0.0, 0.0\n",
    "    running_train_bce, running_train_iou = 0.0, 0.0\n",
    "    train_input, train_output, train_label = None, None, None\n",
    "\n",
    "    for ep in range(epoch):\n",
    "        print(\"{}-{} | Epoch {}\".format(model_name, version, ep))\n",
    "        train_iter, dev_iter = iter(train_loader), iter(dev_loader)\n",
    "        # TRAIN\n",
    "        for _ in tqdm(range(train_num_mini_batches)):\n",
    "            train_input, train_label = train_iter.next()\n",
    "            train_input, train_label = train_input.to(CUDA_DEVICE), train_label.to(CUDA_DEVICE)\n",
    "            # optimizer.zero_grad()\n",
    "            train_output = net(train_input)\n",
    "            train_loss, train_bce, train_iou = compute_loss(train_output, train_label)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += train_loss.item()\n",
    "            running_train_bce += train_bce.item()\n",
    "            running_train_iou += train_iou.item()\n",
    "\n",
    "\n",
    "        # DEV\n",
    "        with torch.no_grad():\n",
    "            for _ in range(dev_num_mini_batches):\n",
    "                dev_input, dev_label = dev_iter.next()\n",
    "                dev_input, dev_label = dev_input.to(CUDA_DEVICE), dev_label.to(CUDA_DEVICE)\n",
    "                dev_output = net(dev_input)\n",
    "                dev_loss, _, _ = compute_loss(dev_output, dev_label)\n",
    "                running_dev_loss += dev_loss.item()\n",
    "\n",
    "        # record loss values after each epoch\n",
    "        cur_train_loss = running_train_loss / train_num_mini_batches\n",
    "        cur_train_bce = running_train_bce / train_num_mini_batches\n",
    "        cur_train_iou = running_train_iou / train_num_mini_batches\n",
    "        cur_dev_loss = running_dev_loss / dev_num_mini_batches\n",
    "        print(\"train loss = {:.4} | val loss = {:.4}\".format(cur_train_loss, cur_dev_loss))\n",
    "        tb.add_scalar('loss/train', cur_train_loss, ep)\n",
    "        tb.add_scalar('loss/train_bce', cur_train_bce, ep)\n",
    "        tb.add_scalar('loss/train_iou', cur_train_iou, ep)\n",
    "        tb.add_scalar('loss/dev', cur_dev_loss, ep)\n",
    "        tb.add_scalar('loss/lr', scheduler._last_lr[0], ep)\n",
    "        if ep % 5 == 0:\n",
    "            tensorboard_vis(tb, ep, mode='train', input_=train_input, output=train_output, label=train_label)\n",
    "            tensorboard_vis(tb, ep, mode='dev', input_=dev_input, output=dev_output, label=dev_label)\n",
    "        running_train_loss, running_dev_loss = 0.0, 0.0\n",
    "        running_train_bce, running_train_iou = 0.0, 0.0\n",
    "        scheduler.step()\n",
    "\n",
    "    print(\"finished training\")\n",
    "    save_network_weights(net, ep=\"{}_FINAL\".format(epoch))\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Specify target GPU, else the one defined in config.py will be used.')\n",
    "    parser.add_argument('--gpu', type=int, help='cuda:$')\n",
    "    args = parser.parse_args()\n",
    "    if args.gpu is not None:\n",
    "        CUDA_DEVICE = \"cuda:{}\".format(args.gpu)\n",
    "    else:\n",
    "        CUDA_DEVICE = \"cpu\".format(args.gpu)\n",
    "    return CUDA_DEVICE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Basics ##################\n",
      "version: v0.10.5-test\n",
      "Training on cpu\n",
      "batch size =  8\n",
      "number of workers =  18\n",
      "#################################\n",
      "Using cross-validation with a 80%/20% train/dev split:\n",
      "dev set: entry 0 to 35 | train set: entry 36 to 179\n",
      "size of train set = 18 mini-batches | size of dev set = 5 mini-batches\n",
      "unet16-v0.10.5-test | Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|███                                                     | 1/18 [00:19<05:25, 19.17s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# net = UNet11(pretrained=True)\u001B[39;00m\n\u001B[1;32m      7\u001B[0m net \u001B[38;5;241m=\u001B[39m UNet16(pretrained\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m----> 8\u001B[0m \u001B[43mtrain_dev\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mload_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpre_trained_params_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m tb\u001B[38;5;241m.\u001B[39mclose()\n",
      "Input \u001B[0;32mIn [4]\u001B[0m, in \u001B[0;36mtrain_dev\u001B[0;34m(net, tb, load_weights, pre_trained_params_path)\u001B[0m\n\u001B[1;32m     39\u001B[0m train_output \u001B[38;5;241m=\u001B[39m net(train_input)\n\u001B[1;32m     40\u001B[0m train_loss, train_bce, train_iou \u001B[38;5;241m=\u001B[39m compute_loss(train_output, train_label)\n\u001B[0;32m---> 41\u001B[0m \u001B[43mtrain_loss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     43\u001B[0m running_train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m train_loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m~/miniconda3/envs/torch110/lib/python3.9/site-packages/torch/_tensor.py:307\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    298\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    299\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    300\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    301\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    305\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[1;32m    306\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[0;32m--> 307\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/torch110/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m retain_graph \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    152\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m--> 154\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "global version, model_name, CUDA_DEVICE\n",
    "CUDA_DEVICE = \"cpu\"\n",
    "model_name, version = \"unet16\", \"v0.10.5-test\"\n",
    "param_to_load = None\n",
    "tb = SummaryWriter('./runs/' + model_name + '-' + version)\n",
    "# net = UNet11(pretrained=True)\n",
    "net = UNet16(pretrained=True)\n",
    "train_dev(net, tb, load_weights=False, pre_trained_params_path=None)\n",
    "tb.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}